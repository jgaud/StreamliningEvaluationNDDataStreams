## Toward Streamlining the Evaluation of Novelty Detection in Data Streams

This repository contains the code used in the empirical tests conducted in the paper *"Toward Streamlining the Evaluation of Novelty Detection in Data Streams"* [1] as well as supplementary results.

This repository is organized as follows:
* **Figures** folder - contains all of the figures extracted from the experiments;
* **Notebooks** folder - contains the Jupyter Notebooks used to plot the figures for the experiments', we suggest looking at those to view the results;
* **Scripts** folder - contains the necessary Python scripts to run the experiments on both synthetic and real datasets. Also shows the hyperparameters used in the experiments;

### Requirements
The experiments were implemented in Python. The code can be executed with the scripts located in the *Scripts* folder.

If you want to replicate the experiments by yourself, a working installation of Python (https://www.python.org/) is required as well as the following packages:

- Our package, StreamNDR (https://pypi.org/project/streamndr/)
- River (https://pypi.org/project/river/)
- Pandas (https://pypi.org/project/pandas/)
- Numpy (https://pypi.org/project/numpy/)
- Matplotlib (https://pypi.org/project/matplotlib/)
- Aim (https://pypi.org/project/aim/)
- Pathos (https://pypi.org/project/pathos/)
- Scikit-Learn (https://pypi.org/project/scikit-learn/)
- SciPy (https://pypi.org/project/scipy/)

### References
[1] Gaudreault, J. G., & Branco, P. (2023, October). Toward Streamlining the Evaluation of Novelty Detection in Data Streams. In International Conference on Discovery Science (pp. 703-717). Cham: Springer Nature Switzerland.
